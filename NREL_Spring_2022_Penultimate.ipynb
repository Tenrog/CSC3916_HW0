{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NREL Spring 2022 Penultimate",
      "provenance": [],
      "collapsed_sections": [
        "QCvFmby41Owq",
        "glgVLC1o20UC",
        "6DWKptBW5Xej"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tenrog/CSC3916_HW0/blob/Patrick's-Branch/NREL_Spring_2022_Penultimate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Random Sketching in GMRes**"
      ],
      "metadata": {
        "id": "tNg5WFjLBipV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Work Breakdown"
      ],
      "metadata": {
        "id": "tjDcXEA4Bj92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Em Gibbs: Main writer, coder. Organized and composed the notebook. Researched sparse matrix sketching. Tested Spring 2021 sketching functions. Assisted with RGMRes coding.\n",
        "* Haonan He: Manager, coder. Researched random skething, RGS Arnoldi, and randomized GMRes. Wrote RGMRes code implmentation.\n",
        "* Patrick Gornet: Main coder, communicator. Led communication with sponsor. Researched classical GMRes. Wrote classical GMRes implementations. Assisted with RGMRes coding."
      ],
      "metadata": {
        "id": "7YQrOuaxBlkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Abstract"
      ],
      "metadata": {
        "id": "4VENh9jODehX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When solving linear systems of equations in the form $Ax = b$ where $A$ and $b$ are given, finding the exact value of $x$ for a large $A$ can be extremely inefficient. Iterative methods like GMRes can speed up this computation time by finding $x$ values that satisfy the equation within a specified margin of error, but are still slow. By introducing random sketching into GMRes, in which $n$ dimensions are randomly embedded into $k$ dimensions such that $k \\ll n$, this project hopes to greatly reduce the computation time of $x$ without loss of accuracy."
      ],
      "metadata": {
        "id": "aXOReZ1WDf86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "wvMUYgTnFHBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The motivation of this project is to accelerate the computation time of GMRes using the process of random sketching on some of the matrices (and vectors) used in the algorithm. By using smaller matrices sketched from the originals, computation time of each iteration of the GMRes algorithm is dramatically reduced, and similar levels of accuracy should be achievable.\n",
        "* The National Renewable Energy Laboratory (NREL), the sponsor of this project, often works with $A$ matrices with dimensions in the billions. Reducing one of those dimensions by a significant factor will more significantly reduce this computation time.\n",
        "* Specifically, this project aims to implement the Randomized Gram-Schmidt algorithm (RGS) described in \"Randomized Gram-Schmidt process with application to GMRES\" by Grigori and Balabanov, where the Modified Gram-Schmidt algorithm (MGS) would otherwise be used in GMRes.\n",
        "* This project therefore will consider pre-existing implementations and pseudocode of GMRes, modifying them or constructing new implementations suited to integrating the random sketching methods defined in the Grigori & Balabanov paper.\n",
        "* When an implementation of GMRes with random sketching is fully developed, this project will test this implemenation against other GMRes implementations for computational time and accuracy."
      ],
      "metadata": {
        "id": "bumcJR6GFIpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Methods"
      ],
      "metadata": {
        "id": "ZYRSIU6GGBfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "wOAxhGNLGE11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "from scipy.sparse import csc_matrix\n",
        "from scipy.sparse.linalg import gmres\n",
        "from scipy.sparse.linalg import lgmres\n",
        "from scipy.sparse import random as rand_sparse"
      ],
      "metadata": {
        "id": "qm8RqOgLGGEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classical GMRes Implementations"
      ],
      "metadata": {
        "id": "T8vZAkCyqyBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SciPy GMRes"
      ],
      "metadata": {
        "id": "QCvFmby41Owq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the use of Python in developing an implementation of randomized GMRes (RGMRes), we considered the SciPy package, whose linear algebra package includes an implementation of GMRes."
      ],
      "metadata": {
        "id": "BTdERfqLq6au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code tests the runtime of SciPy's GMRes for matrices of size $100 \\times 100$, $750 \\times 750$, and $1250 \\times 1250$, as well as the number of iterations, and error of their results. These will form a baseline for comparison developing further implementations."
      ],
      "metadata": {
        "id": "YkdDkhIksMR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, for the purpose of counting iterations, the following gmres_counter() function was taken from [Stack Overflow](https://stackoverflow.com/questions/33512081/getting-the-number-of-iterations-of-scipys-gmres-iterative-method) and will be used later as well."
      ],
      "metadata": {
        "id": "_5uSUtJn9wO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class gmres_counter(object):\n",
        "    def __init__(self, disp=True):\n",
        "        self._disp = disp\n",
        "        self.niter = 0\n",
        "    def __call__(self, rk=None):\n",
        "        self.niter += 1\n",
        "        return self.niter"
      ],
      "metadata": {
        "id": "E7l8RfITtJ_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#array of sizes\n",
        "size = [100, 750, 1250]\n",
        "\n",
        "#loop through sizes\n",
        "for curr_size in size:\n",
        "  #variable declaration\n",
        "  A = np.random.rand(curr_size,curr_size)\n",
        "  xTrue = np.random.rand(curr_size)\n",
        "  xNorm = np.sqrt(np.average((xTrue)**2))\n",
        "  b = np.dot(A,xTrue)\n",
        "  counter = gmres_counter()\n",
        "  x_0 = np.zeros(curr_size)\n",
        "\n",
        "  #timing GMRes and calculating error\n",
        "  t1 = time.perf_counter()\n",
        "  x = gmres(A,b, x_0, restart=1000, callback = counter)[0]\n",
        "  t2 = time.perf_counter()\n",
        "  error = np.sqrt(np.average((xTrue - x)**2))/xNorm\n",
        "\n",
        "  print(\"For\", curr_size, \"x\", curr_size, \":\")\n",
        "  print(\"Error:\", error)\n",
        "  print(\"Iterations:\", counter()-1)\n",
        "  print(\"Time: \", t2 - t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3Ge0jNkueap",
        "outputId": "7ade87bf-b6f9-414c-c286-a3cc1db0a99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 100 x 100 :\n",
            "Error: 6.6888008892898445e-15\n",
            "Iterations: 100\n",
            "Time:  0.008965910000370059\n",
            "For 750 x 750 :\n",
            "Error: 0.04634160882068907\n",
            "Iterations: 749\n",
            "Time:  0.38924825899994175\n",
            "For 1250 x 1250 :\n",
            "Error: 0.48458613291381025\n",
            "Iterations: 12500\n",
            "Time:  15.060490763999951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code does the same as the above code, but with sparse matrices of density 0.1."
      ],
      "metadata": {
        "id": "L66DRZ2pyhEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of sizes\n",
        "size = [100, 750, 1250]\n",
        "\n",
        "#loop through sizes\n",
        "for curr_size in size:\n",
        "  #variable declaration\n",
        "  A = rand_sparse(curr_size, curr_size, density=0.1).toarray()\n",
        "  xTrue = np.random.rand(curr_size)\n",
        "  xNorm = np.sqrt(np.average((xTrue)**2))\n",
        "  b = np.dot(A,xTrue)\n",
        "  counter = gmres_counter()\n",
        "  x_0 = np.zeros(curr_size)\n",
        "\n",
        "  #timing GMRes and calculating error\n",
        "  t1 = time.perf_counter()\n",
        "  x = gmres(A,b, x_0, restart=1000, callback = counter)[0]\n",
        "  t2 = time.perf_counter()\n",
        "  error = np.sqrt(np.average((xTrue - x)**2))/xNorm\n",
        "\n",
        "  print(\"For\", curr_size, \"x\", curr_size, \":\")\n",
        "  print(\"Error:\", error)\n",
        "  print(\"Iterations:\", counter()-1)\n",
        "  print(\"Time: \", t2 - t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hGnxPEYyl1P",
        "outputId": "5d20d06b-e1bf-40a3-ec0b-38e19537520a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 100 x 100 :\n",
            "Error: 5.797220796177716e-14\n",
            "Iterations: 100\n",
            "Time:  0.0041206249998140265\n",
            "For 750 x 750 :\n",
            "Error: 4.297211446240082e-14\n",
            "Iterations: 750\n",
            "Time:  0.39393633400004546\n",
            "For 1250 x 1250 :\n",
            "Error: 0.5225190666080766\n",
            "Iterations: 12500\n",
            "Time:  14.81432392700026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given these relatively fast implementations implementations of GMRes, we would like to build off of them with sketching, but their source code is more complicated than necessary for the purposes of this project."
      ],
      "metadata": {
        "id": "VMb-_aZD1X-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Wikipedia MatLab to Python GMRes"
      ],
      "metadata": {
        "id": "glgVLC1o20UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another implementation of GMRes considered was that provided by the Wikipedia page for GMRES. This page provides the code for a [MatLab implementation](https://en.wikipedia.org/wiki/Generalized_minimal_residual_method#Regular_GMRES_(MATLAB_/_GNU_Octave), and given MatLab's similarity to Python, we considered translating this code to Python, with the following results."
      ],
      "metadata": {
        "id": "_Gdvoi6i26f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function assumes that inputs are numpy arrays\n",
        "def gmresWiki( A, b, x, max_iterations, threshold):\n",
        "  n = max(np.shape(A))\n",
        "  m = max_iterations\n",
        "\n",
        "  # use x as the initial vector\n",
        "  r = np.subtract(b, A.dot(x))\n",
        "\n",
        "  b_norm = np.linalg.norm(b)\n",
        "  error = np.divide(np.linalg.norm(r), b_norm)\n",
        "\n",
        "  # initialize the 1D vectors\n",
        "  sn = np.zeros((m, 1))\n",
        "  cs = np.zeros((m, 1))\n",
        "  #e1 = np.zeros((n, 1))\n",
        "  e1 = np.zeros((m+1, 1))\n",
        "  e1[0] = 1\n",
        "  e = np.array([error])\n",
        "  r_norm = np.linalg.norm(r)\n",
        "\n",
        "  Q = np.reshape(np.array(np.divide(r, r_norm)),(-1,1))\n",
        "\n",
        "  beta = np.multiply(r_norm, e1)     #Note: this is not the beta scalar in section \"The method\" above but the beta scalar multiplied by e1\n",
        "  \n",
        "  for k in range(m):\n",
        "    print(k)\n",
        "    # run arnoldi\n",
        "\n",
        "    htemp, qtemp= arnoldiWiki(A, Q, k)\n",
        "    H = np.hstack(H, np.transpose(htemp))\n",
        "    Q = np.vstack(Q, qtemp)\n",
        "    \n",
        "    # eliminate the last element in H ith row and update the rotation matrix\n",
        "    htemp, cs[k,0], sn[k,0], = apply_givens_rotation(H[:,k], cs, sn, k)\n",
        "    H = np.hstack(H, np.transpose(htemp))\n",
        "    # update the residual vector\n",
        "    beta[k + 1, 0] = -sn[k,0] * beta[k, 0]\n",
        "    beta[k, 0]     = cs[k,0] * beta[k, 0]\n",
        "    error       = abs(np.divide(beta[k + 1, 0], b_norm))\n",
        "\n",
        "    # save the error\n",
        "    e = np.vstack(e, error)\n",
        "\n",
        "    if (error <= threshold):\n",
        "      break\n",
        "    \n",
        "  \n",
        "  # if threshold is not reached, k = m at this point (and not m+1) \n",
        "  \n",
        "  # calculate the result\n",
        "  y = np.divide(H,beta)\n",
        "  x = x + Q[:,0:k] * y\n",
        "  return x, e\n",
        "\n",
        "\n",
        "#Arnoldi Function\n",
        "\n",
        "def arnoldiWiki(A, Q, k):\n",
        "    q = np.multiply(A,Q[:,k])   # Krylov Vector\n",
        "    h = np.zeros((1,k))\n",
        "    for i in range(k):    # Modified Gram-Schmidt, keeping the Hessenberg matrix\n",
        "        h[0,i] = np.multiply(np.transpose(q), Q[:, i])\n",
        "        q = np.subtract(q, np.multiply(h[0:i], Q[:, i]))\n",
        "    print(np.linalg.norm(q, axis = 0)[1,1])\n",
        "    h = np.append(h, [[np.linalg.norm(q)]])\n",
        "    q = np.divide(q, h[0, k + 1])\n",
        "    return h, q\n",
        "\n",
        "\n",
        "#Applying Givens Rotation to H col\n",
        "\n",
        "def apply_givens_rotation(h, cs, sn, k):\n",
        "  # apply for ith column\n",
        "    for i  in range(k-1):\n",
        "        temp   = np.add(np.multiply(cs[i, 0], h[i, 0]), np.multiply(sn[i, 0], h[i + 1, 0]))\n",
        "        h[i + 1, 0] = np.add(np.multiply(-sn[i, 0], h[i, 0]), np.multiply(cs[i, 0], h[i + 1, 0]))\n",
        "        h[i, 0]  = temp\n",
        "  \n",
        "    # update the next sin cos values for rotation\n",
        "    cs_k, sn_k = givens_rotation(h[k, 0], h[k + 1, 0])\n",
        "\n",
        "    # eliminate H(i + 1, i)\n",
        "    h[k, 0] = np.add(np.multiply(cs_k, h[k, 0]), np.multiply(sn_k, h[k + 1, 0]))\n",
        "    h[k + 1, 0] = 0.0\n",
        "    return h, cs_k, sn_k\n",
        "\n",
        "#Calculate the Givens rotation matrix\n",
        "def givens_rotation(v1, v2):\n",
        "\n",
        "    t = np.sqrt(np.add(np.power(v1, 2), np.power(v2, 2)))\n",
        "    cs = np.divide(v1, t) \n",
        "    sn = np.divide(v2, t)\n",
        "    return cs, sn"
      ],
      "metadata": {
        "id": "yz2EDRnw39C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the above code does not run in its current state, the exercise of translating it was valuable in building understanding of GMRes. Unfortunately, the use of the Givens rotation made it incompatible with RGMRes as defined by the Balabanov & Grigori paper, so it is not suitable for building upon."
      ],
      "metadata": {
        "id": "c0S82DAc42n4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sauer Numerical Analysis GMRes"
      ],
      "metadata": {
        "id": "6DWKptBW5Xej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we considered the GMRes pseudocode as defined by the Numerical Analysis 3rd Edition textbook by Timothy Sauer. The pseudocode is as follows:"
      ],
      "metadata": {
        "id": "vcacwxWd5dQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$x_{0} =$ initial guess\n",
        "\n",
        "$r = b - Ax_{0}$\n",
        "\n",
        "$q_{1} = r / ||r||_{2}$\n",
        "\n",
        "**for** $k = 1, 2, ..., m$\n",
        "\n",
        ">$y = Aq_{k}$\n",
        "\n",
        ">**for** $j = 1, 2, ..., k$\n",
        "\n",
        ">>$h_{jk} = q_{j}^{T}y$\n",
        "\n",
        ">>$y = y - h_{jk}q_{j}$\n",
        "\n",
        ">**end**\n",
        "\n",
        ">$h_{k+1,k} = ||y||_{2}$ (If $h_{k+1,k} = 0$, skip next line and terminate at bottom.)\n",
        "\n",
        "> $q_{k+1} = y/h_{k+1,k}$\n",
        "\n",
        "> Minimize $||Hc_{k} - [||r||_{2} \\: 0 \\:0 \\: ... 0]^{T}||_{2}$ for $c_{k}$\n",
        "\n",
        ">$x_{k} = Q_{k}c_{k} + x_{0}$\n",
        "\n",
        "**end**"
      ],
      "metadata": {
        "id": "Ix0VqGYs589I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the above pseudocode, the following implementation was developed."
      ],
      "metadata": {
        "id": "-5SVAryt9joF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def leastSqr (H, b_temp):\n",
        "    c = np.linalg.lstsq(H,b_temp, rcond=None)[0]\n",
        "    return c\n",
        "\n",
        "def SauerGMRes (A, b, x0, max_iterations = 1000, threshold = 0.000001):\n",
        "    max_iterations = min(max_iterations, max(np.shape(A)))\n",
        "    # Ax = b\n",
        "    # A in input matrix\n",
        "    # b is vector\n",
        "    # x0 is initial guess vector\n",
        "    # r = b - Ax_0\n",
        "    r = np.subtract(b, np.asarray(np.dot(A, x0)).reshape(-1))\n",
        "    x = []\n",
        "    Q = [0] * (max_iterations)\n",
        "    #calculate forward and backward error\n",
        "    #ensure backward error is going down\n",
        "    x.append(r)\n",
        "\n",
        "    # q1 = r/||r||_2\n",
        "    Q[0] = np.divide(r, np.linalg.norm(r))\n",
        "\n",
        "    H = np.zeros((max_iterations + 1, max_iterations)) #have H expand and initilize b here\n",
        "    steps = 0\n",
        "    #Iterate\n",
        "    for k in range(max_iterations):\n",
        "        # y = Aq_k\n",
        "        y = np.asarray(np.dot(A, Q[k])).reshape(-1)\n",
        "        \n",
        "        for j in range(k):\n",
        "            # h_(jk) = q_j^T*y\n",
        "            H[j, k] = np.dot(Q[j], y)\n",
        "            # y = y - h_(jk)q_j\n",
        "            y = np.subtract(y, np.multiply(H[j, k], Q[j]))\n",
        "        \n",
        "        # h_(k+1,k) = ||y||_2\n",
        "        H[k + 1, k] = np.linalg.norm(y)\n",
        "        # Checking if h_(k+1,k) is 0\n",
        "        if (H[k + 1, k] != 0 and k != max_iterations - 1):\n",
        "          # q_(k+1) = y/h_(k+1,k)\n",
        "          Q[k + 1] = np.divide(y, H[k + 1, k])\n",
        "        else:\n",
        "          steps = k\n",
        "          break\n",
        "        \n",
        "        # Creating vector [||r||_2, 0, 0, ..., 0]^T\n",
        "        b_temp = np.zeros(max_iterations + 1) #possiable problem, should be k\n",
        "        b_temp[0] = np.linalg.norm(r)\n",
        "        # Minimize ||Hc_k - [||r||_2, 0, 0, ..., 0]^T||_2 for c_k\n",
        "        c = leastSqr(H, b_temp)\n",
        "        # x_k = Q_kc_k+x_0\n",
        "        x.append(np.add(np.dot(np.asarray(Q).transpose(), c), x0))\n",
        "    \n",
        "    \n",
        "    return x[-1], steps"
      ],
      "metadata": {
        "id": "TMNbrxdS-BU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code tests this implementation of GMRes against SciPy."
      ],
      "metadata": {
        "id": "pVIqe5PA-as-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: At time of last execution, it took over 150 seconds for the Sauer GMRes implementation to solve the problem with an A matrix of size $750 \\times 750$, and it did not solve the $1250 \\times 1250$ problem."
      ],
      "metadata": {
        "id": "2tYaRBBOAVeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of sizes\n",
        "#size = [100, 750, 1250]\n",
        "size = [100]\n",
        "\n",
        "#loop through sizes\n",
        "for curr_size in size:\n",
        "  #variable declaration\n",
        "  A = np.random.rand(curr_size, curr_size)\n",
        "  xTrue = np.random.rand(curr_size)\n",
        "  xNorm = np.sqrt(np.average((xTrue)**2))\n",
        "  b = np.dot(A,xTrue)\n",
        "  counter = gmres_counter()\n",
        "  x_0 = np.zeros(curr_size)\n",
        "\n",
        "  #timing SciPy GMRes and calculating error\n",
        "  t1 = time.perf_counter()\n",
        "  x = gmres(A,b, x_0, restart=1000, callback = counter)[0]\n",
        "  t2 = time.perf_counter()\n",
        "  error = np.sqrt(np.average((xTrue - x)**2))/xNorm\n",
        "\n",
        "  print(\"For\", curr_size, \"x\", curr_size, \":\")\n",
        "  print(\"SciPy GMRes\")\n",
        "  print(\"Error:\", error)\n",
        "  print(\"Iterations:\", counter()-1)\n",
        "  print(\"Time: \", t2 - t1)\n",
        "\n",
        "  #timing Sauer GMRes and calculating error\n",
        "  t1 = time.perf_counter()\n",
        "  x, k = SauerGMRes(A, b, x_0)\n",
        "  t2 = time.perf_counter()\n",
        "  error = np.sqrt(np.average((xTrue - x)**2))/xNorm\n",
        "\n",
        "  print(\"Sauer GMRes\")\n",
        "  print(\"Error:\", error)\n",
        "  print(\"Iterations:\", k)\n",
        "  print(\"Time: \", t2 - t1)\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyRk5N-T-aV5",
        "outputId": "6b318318-3e4d-42b4-c506-7524d6c7ce03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 100 x 100 :\n",
            "SciPy GMRes\n",
            "Error: 1.9660669632128094e-14\n",
            "Iterations: 100\n",
            "Time:  0.004272920999937924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sauer GMRes\n",
            "Error: 0.4003400942464691\n",
            "Iterations: 99\n",
            "Time:  0.26527165500010597\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the Sauer GMRes implementation takes much longer than SciPy's, we can aniticipate that introducing sketching will reduce runtime significantly from the classical implementation."
      ],
      "metadata": {
        "id": "D9CvU1MhBaSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Sketching"
      ],
      "metadata": {
        "id": "nLtOg_mpFTO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Important Functions"
      ],
      "metadata": {
        "id": "V5qLkZBMH2zF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions are taken from the Spring 2021 NREL Math Clinic project, and are important for testing later in this section and elsewhere in the notebook."
      ],
      "metadata": {
        "id": "RRHj5n7PH9-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining important functions\n",
        "\n",
        "#Defining matrix multiplication function\n",
        "def mat_mul(x,y):\n",
        "  return np.matmul(x,y) #AF: coders asked to write a faster code based on Θ structure\n",
        "\n",
        "#Building Θ Matrix\n",
        "def Theta_Matrix(k,n): #AF: brute force implementation\n",
        "  Theta = (np.random.randint(0,2,size=(k,n))*2-1)*math.sqrt(k)**-1\n",
        "  return Theta\n",
        "\n",
        "#Finds smallest possible k from inequality 3a using values set above.\n",
        "def mink(ϵ, d, δ):                           # δ, ϵ are local here\n",
        "  min_k = 7.87*ϵ**-2*(6.9*d + math.log(1/δ)) #AF: Grigori & Balabanov (3a)\n",
        "  return min_k\n",
        "  \n",
        "def xIterCompare(xTrue, xOld, xNew):\n",
        "  xTrueNorm = np.sqrt(np.average((xTrue)**2))\n",
        "  oldError = np.sqrt(np.average((xTrue - xOld)**2))/xTrueNorm\n",
        "  newError = np.sqrt(np.average((xTrue - xNew)**2))/xTrueNorm\n",
        "  return oldError, newError\n",
        "\n",
        "def xAccuracy(xTrue, x):\n",
        "  xTrueNorm = np.sqrt(np.average((xTrue)**2))\n",
        "  error = np.sqrt(np.average((xTrue - x)**2))/xTrueNorm\n",
        "  return error"
      ],
      "metadata": {
        "id": "ey1FxAi1IHhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Balabanov & Grigori Inequality 2.1"
      ],
      "metadata": {
        "id": "3PUUULrtGle6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following inequality is defined as Definition 2.1 in the Balabanov and Grigori paper (i.e., the definition of an ϵ-subspace embedding for V):\n",
        "$$∀x, y∈V; |<x;y> - <Θx;Θy>| ≤ ε||x||⋅||y||$$ \n",
        "\n",
        "For a sketching matrix Θ, δ is equal to the failure rate of inequality 2.1.\n",
        "\n",
        "The following code blocks test various random vectors x and y from V to determine a failure rate δ for inequality 2.1. The function inequality2 is taken from the Spring 2021 NREL Math Clinic project.\n",
        "\n",
        "By choosing and varying k and d in the generation of the Θ matrix, we hope to discover ε and δ values using the following inequality 2.2a:\n",
        "\n",
        "$$k≥7.87ε^{-2}(6.9d + log(1/δ))$$"
      ],
      "metadata": {
        "id": "Q_9XM47pGpjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inequality2(V, d, Θ, ϵ):\n",
        "  #Getting x and y arrays in V subspace\n",
        "  a = np.random.normal(0,1,d) \n",
        "  x_from_V =  mat_mul(V, a)\n",
        "  b = np.random.normal(0,1,d) \n",
        "  y_from_V = mat_mul(V, b)\n",
        "  #Matrix vector products of Θ and x,y\n",
        "  theta_x = mat_mul(Θ, x_from_V)\n",
        "  theta_y = mat_mul(Θ, y_from_V)\n",
        "  #Calculate right and left hand side of the equation\n",
        "  LHS = abs(np.inner(x_from_V,y_from_V) - np.inner(theta_x, theta_y))\n",
        "  RHS = ϵ*np.linalg.norm(x_from_V)*np.linalg.norm(y_from_V)\n",
        "  #Comparing RHS to LHS   \n",
        "  if LHS <= RHS:  #AF: I asked to return and inspect (RHS – LHS) to see how close the success is\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "#Test function for inequality 2\n",
        "def test_inequality2(num_iters, V, d, Θ, ϵ):\n",
        "  passes = 0\n",
        "  failures = 0\n",
        "  for i in range(num_iters):\n",
        "    if inequality2(V, d, Θ, ϵ):\n",
        "      passes += 1\n",
        "    else:\n",
        "      failures += 1\n",
        "\n",
        "  return failures / (failures + passes)"
      ],
      "metadata": {
        "id": "frGzd7-RJOpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign variables\n",
        "n = 5000\n",
        "ϵ = 1/2\n",
        "d = [5, 50, 500]\n",
        "k = [500, 1000, 2000, 4000]\n",
        "\n",
        "for d_iter in d:\n",
        "  for k_iter in k:\n",
        "    #generate theta\n",
        "    Θ = Theta_Matrix(k_iter, n)\n",
        "    V = np.random.normal(0, 1, (n, d_iter))\n",
        "\n",
        "    #iterate test inequality 2.1 100 times\n",
        "    iter = 100\n",
        "    failrate = test_inequality2(iter, V, d_iter, Θ, ϵ)\n",
        "\n",
        "    print(\"For k = \", k_iter, \", d = \", d_iter, \":\")\n",
        "    print(\"Failure rate = \", failrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UybXccXoJvzK",
        "outputId": "88bbd26e-c552-4bcf-ab20-0ec3c75b62e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For k =  500 , d =  5 :\n",
            "Failure rate =  0.0\n",
            "For k =  1000 , d =  5 :\n",
            "Failure rate =  0.0\n",
            "For k =  2000 , d =  5 :\n",
            "Failure rate =  0.0\n",
            "For k =  4000 , d =  5 :\n",
            "Failure rate =  0.0\n",
            "For k =  500 , d =  50 :\n",
            "Failure rate =  0.0\n",
            "For k =  1000 , d =  50 :\n",
            "Failure rate =  0.0\n",
            "For k =  2000 , d =  50 :\n",
            "Failure rate =  0.0\n",
            "For k =  4000 , d =  50 :\n",
            "Failure rate =  0.0\n",
            "For k =  500 , d =  500 :\n",
            "Failure rate =  0.0\n",
            "For k =  1000 , d =  500 :\n",
            "Failure rate =  0.0\n",
            "For k =  2000 , d =  500 :\n",
            "Failure rate =  0.0\n",
            "For k =  4000 , d =  500 :\n",
            "Failure rate =  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Spring 2021 NREL Math Clinic team also tested several possible values for these variables in the inequality 2.1, but could never get the inequality to fail as long as other necessary inequalities for the variables still held. This seemed strange, as we then have no basis for the selection of δ. However, we can see that these variable tests also produced no failures of the inequality, so we will continue to use the Spring 2021 chosen variable values (δ of 0.9 and ε of 1/2)."
      ],
      "metadata": {
        "id": "ZsFOeyRKKLQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Spring 2021 Randomized Gram-Schmidt"
      ],
      "metadata": {
        "id": "3uLUAheYNCje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions are taken from the Spring 2021 NREL Math Clinic project. This code block has an implementation of Gram-Schmidt taken from Professor Liu, and their implementation of Randomized Gram-Schmidt (RGS)."
      ],
      "metadata": {
        "id": "67QT6EtxNGRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'(Liu)'\n",
        "'Used to compare RGS with classic GS'\n",
        "def reduced_QR(A):\n",
        "  \"\"\"\n",
        "  Perform reduced QR factorization with Gram Schmidt orthogonalization\n",
        "  for the columns of Areturn Q: a matrix of size m x n with orthonormal columns\n",
        "  R: an upper triagular matrix of size n x n\n",
        "  \"\"\"\n",
        "  n, m = A.shape                          #AF: m, n swapped cf. rest of code\n",
        "  Q = np.zeros((n,m))\n",
        "  R = np.zeros((m,m))\n",
        "  for i in range(m):\n",
        "    y = A[:, i]\n",
        "    for j in range(i):\n",
        "      R[j,i] = np.dot(Q[:,j], A[:,i])\n",
        "      y = y - R[j,i]*Q[:,j]\n",
        "    R[i,i] = np.linalg.norm(y)\n",
        "    Q[:,i] = y/R[i,i]\n",
        "\n",
        "    #print(\"Reduced QR\")\n",
        "    #print(\"R[i,i]\", R[i,i])\n",
        "  return Q, R\n",
        "\n",
        "def rand_QR(A, k):\n",
        "  #Setting Values                           #AF: B&G Algo. 2 requires m ≤ k << n\n",
        "  m = A.shape[1]\n",
        "  n = A.shape[0]\n",
        "  Θ = Theta_Matrix(k,n)\n",
        "  #Setting zero matrices to build\n",
        "  Q = np.zeros((n,m))\n",
        "  R = np.zeros((m,m))                       #AF: could use sparse structure\n",
        "  S = np.zeros((k,m))                       #AF: S need not be formed\n",
        "  p = np.dot(Θ, A)                          #AF: p need not be formed\n",
        "  for i in range(m):                        #AF: So i here is i–1 in RGS_balabanov_grigori_2020.pdf\n",
        "    #steps 2, 3:\n",
        "    if i == 0:\n",
        "      #step 3\n",
        "      q_prime_i = A[:,i]\n",
        "    else:\n",
        "      new_holder = S[:,i-1]                 #AF: B&G Algo. 2 says S[:,:i] not S[:,i-1]\n",
        "      new_holder = np.reshape(new_holder, (k,1))\n",
        "      holder = np.linalg.pinv(new_holder)   #AF: the pinv of a tall S is always (S⸆S)⁻¹S⸆\n",
        "      r_i = np.dot(holder, p)               #AF: np.linalg.solve(S⸆S,S⸆p) would be faster\n",
        "      R[i-1,:] = r_i                        #AF: not indexed like B&G Algo. 2 step 2\n",
        "      q_prime_i = A[:,i] - np.dot(Q, R[:,i])#AF: not indexed like B&G Algo. 2 step 3\n",
        "    #step 4\n",
        "    s_prime_i = np.dot(Θ, q_prime_i)\n",
        "    #step 5\n",
        "    r = np.linalg.norm(s_prime_i)\n",
        "    #step 6\n",
        "    s_i = s_prime_i/r\n",
        "    #step 7\n",
        "    q_i = q_prime_i/r\n",
        "    #Building Q, R, S\n",
        "    Q[:,i] = q_i\n",
        "    S[:,i] = s_i\n",
        "    if i==(m-1):                            #AF: this whole block is some ghastly kluge against above errors\n",
        "      new_holder = S[:,i]\n",
        "      new_holder = np.reshape(new_holder, (k,1))\n",
        "      holder = np.linalg.pinv(new_holder)\n",
        "      r_i = np.dot(holder, p)\n",
        "      R[i,:] = r_i\n",
        "      for k in range(m):\n",
        "        R[k+1:,k] = 0\n",
        "  return Q, R"
      ],
      "metadata": {
        "id": "8oxfreEINQ72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, the following function RGS_testing was also taken from the Spring 2021 project, but modified slightly."
      ],
      "metadata": {
        "id": "pS6WWATuNdyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Numerical Stability Test\n",
        "#iter is number of iterations\n",
        "def RGS_testing(iter, A, k):\n",
        "  results = []\n",
        "  times = []\n",
        "  for i in range(iter):\n",
        "    #Performing the QR decompositions and tracking the time\n",
        "    tic = time.perf_counter()\n",
        "    GS_Q, GS_R = reduced_QR(A)\n",
        "    toc = time.perf_counter()\n",
        "    GS_time = toc - tic\n",
        "    tic = time.perf_counter()\n",
        "    RGS_Q, RGS_R = rand_QR(A, k)\n",
        "    toc = time.perf_counter()\n",
        "    RGS_time = toc - tic\n",
        "    time_diff = GS_time - RGS_time\n",
        "    #Finding and comparing the accuracy of the two methods\n",
        "    GS_results = A - mat_mul(GS_Q, GS_R)\n",
        "    GS_Ortho = np.identity(np.shape(A)[1]) - GS_Q.T @ GS_Q\n",
        "    RGS_results = A - mat_mul(RGS_Q, RGS_R)\n",
        "    RGS_Ortho = np.identity(np.shape(A)[1]) - RGS_Q.T @ RGS_Q\n",
        "    GS_norm = np.linalg.norm(GS_results)/np.linalg.norm(A)\n",
        "    RGS_norm = np.linalg.norm(RGS_results)/np.linalg.norm(A)\n",
        "    GS_Onorm = np.linalg.norm(GS_Ortho)/(np.sqrt(np.shape(A)[1]))\n",
        "    RGS_Onorm = np.linalg.norm(RGS_Ortho)/(np.sqrt(np.shape(A)[1]))\n",
        "    accuracy = (GS_norm, RGS_norm, GS_Onorm, RGS_Onorm)\n",
        "    #Setting results\n",
        "    results.append(accuracy)\n",
        "    times.append(time_diff)\n",
        "  return results, times"
      ],
      "metadata": {
        "id": "fwV3qIDpNgHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code was slightly modified from the Spring 2021 project and comapres runtime and accuracy of GS and their implementation of RGS."
      ],
      "metadata": {
        "id": "ljbWWq2sOfHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#variable declarations\n",
        "n = 1000\n",
        "m = 500\n",
        "k = 750\n",
        "\n",
        "A = np.random.rand(n, m)\n",
        "iter = 3\n",
        "\n",
        "#run tests\n",
        "results, times = RGS_testing(iter, A, k)\n",
        "\n",
        "#print results\n",
        "for i in range(iter):\n",
        "  print(\"On iteration\", i)\n",
        "  print(\"The accuracy difference was: \" + str(results[i]))\n",
        "  print(\"The time difference was: \" + str(times[i]))\n",
        "  if times[i] < 0:\n",
        "    print(\"Gram Schmidt was quicker than RGS here.\")\n",
        "  elif times[i] == 0:\n",
        "    print(\"RGS and GS took the same time here.\")\n",
        "  else:\n",
        "    print(\"RGS was quicker than GS here.\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgCob0v7N3qY",
        "outputId": "cef276b1-3fb5-44e6-e8ca-edd57f642f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On iteration 0\n",
            "The accuracy difference was: (6.638410798977528e-16, 3.5330340197700863e-15, 1.7947338713753687e-14, 4.7265790389175155)\n",
            "The time difference was: 3.734614910000005\n",
            "RGS was quicker than GS here.\n",
            "\n",
            "\n",
            "On iteration 1\n",
            "The accuracy difference was: (6.638410798977528e-16, 3.126121033919637e-15, 1.7947338713753687e-14, 4.742457005947366)\n",
            "The time difference was: 3.2764480959999958\n",
            "RGS was quicker than GS here.\n",
            "\n",
            "\n",
            "On iteration 2\n",
            "The accuracy difference was: (6.638410798977528e-16, 3.092920635854113e-15, 1.7947338713753687e-14, 4.757408615360058)\n",
            "The time difference was: 3.3479587459999607\n",
            "RGS was quicker than GS here.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the RGS function runs much faster than the MGS function, the accuracy is not as good. Without spending more time working with the code, it is hard to say what is causing this inflated error."
      ],
      "metadata": {
        "id": "ek2GmeNHSwRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the Spring 2021 NREL Math Clinic team managed to develop a working Randomized Gram-Schmidt function, there are issues with the accuracy that make it worrisome to implement. Additionally, the function is not constructed in a way that is conducive to implementing it into a full RGMRes. Rather than trying to debug and modify the code to work for us, we opted to develop our own implementation of the full RGMRes as described in the Grigori & Balabanov paper."
      ],
      "metadata": {
        "id": "s3gWnDAqTMPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Algo_2"
      ],
      "metadata": {
        "id": "fmt2kYGfWFhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function my_sketch, allows us to define whether to run our algorithm 2 and RGMRes implementations with sketching or not."
      ],
      "metadata": {
        "id": "bAhVmt8Jl2h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sketch = False\n",
        "if (sketch):\n",
        "  def my_sketch(sketch_mat, mat):\n",
        "    return sketch_mat @ mat\n",
        "else:\n",
        "    def my_sketch(sketch_mat, mat):\n",
        "      return mat\n"
      ],
      "metadata": {
        "id": "_mpvhZi8l2OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We developed our own implementation of randomized GMRes. This function is defined as algo_2. The following code defines algo_2, as well as a modified RGS_testing function for comparison."
      ],
      "metadata": {
        "id": "SBsVzNoSUO3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Balabanov & Grigori Algorithm 2 (RGS)\n",
        "#Parameters: nxm array W, kxn array sketch_mat, boolean sketch\n",
        "#Returns: nxm factor Q, mxm upper triangular factor R\n",
        "def algo_2(W, sketch_mat):\n",
        "    #Getting sizes of matrices\n",
        "    n, m = W.shape\n",
        "    k = len(sketch_mat)\n",
        "\n",
        "    #Initializing zero matrices\n",
        "    S = np.zeros((n,m))\n",
        "    S = my_sketch(sketch_mat, S)\n",
        "    Q = np.zeros((n,m))\n",
        "    R = np.zeros((m,m))\n",
        "\n",
        "    #RGS Algorithm\n",
        "    for i in range(m):\n",
        "        #2.1: Sketch w_i: p_i = Θw_i\n",
        "        p = my_sketch(sketch_mat, W[:,i])\n",
        "\n",
        "        q_p = W[:,i]\n",
        "        #2.2: Solve k x (i-1) least-squares problem:\n",
        "        #   R_1:i-1,i = arg min_y ||(S_i-1)y - p_i||\n",
        "        #   lstsq method\n",
        "        #R[:i-1,i] = np.linalg.lstsq(S[:,:i-1], p)[0]\n",
        "        #   pinv method\n",
        "        #S_pinv = np.linalg.pinv(S[:,:i-1])\n",
        "        #R[:i-1,i] = np.dot(S_pinv,p)\n",
        "\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"At RGS iteration \", i)\n",
        "        print(i-1)\n",
        "        print(\"R[:i-1,i] after lstsq\")\n",
        "        print(R[:i-1,i])\n",
        "        print(\"p\")\n",
        "        print(p)\n",
        "        print(\"S[:,:i-1]\")\n",
        "        print(S[:,:i-1])\n",
        "        print()\n",
        "        \"\"\"\n",
        "\n",
        "        #   fournier method\n",
        "        S_sub = S[:,:i]\n",
        "        StS = np.dot(S_sub.transpose(),S_sub)\n",
        "        Stp = np.dot(S_sub.transpose(), p)\n",
        "        R[:i,i] = np.linalg.solve(StS, Stp)\n",
        "        #   liu method\n",
        "        #for j in range(i):\n",
        "        #    R[j,i] = np.dot(Q[:,j], W[:,i])\n",
        "        #    q_p = q_p - R[j,i]*Q[:,j]\n",
        "        #2.3: Compute projection of w_i: q_i_p = w_i - (Q_i-1)R_1:i-1,i\n",
        "        q_p = q_p - np.dot(Q[:,:i],R[:i,i])\n",
        "        #2.4: Sketch q_i_p: s_i_p = Θq_i_p\n",
        "        s_p = my_sketch(sketch_mat, q_p)\n",
        "        #2.5: Compute the sketched norm r_i,i = ||s_i_p||\n",
        "        R[i,i] = np.linalg.norm(s_p)\n",
        "        #2.6: Scale vector s_i = s_i_p/r_i.i\n",
        "        S[:,i] = s_p/R[i,i]\n",
        "        #2.7: Scale vector q_i = q_i_p/r_i.i\n",
        "        Q[:,i] = q_p/R[i,i]\n",
        "\n",
        "        #print(\"Algo 2\")\n",
        "        #print(\"R[i,i]\", R[i,i])\n",
        "    return Q, R\n",
        "\n",
        "def RGS_testing_2(iter, W, k):\n",
        "    results = []\n",
        "    times = []\n",
        "    for i in range(iter):\n",
        "        sketch_mat=Theta_Matrix(k,n)\n",
        "        tic = time.perf_counter()\n",
        "        GS_Q, GS_R = reduced_QR(W)\n",
        "        toc = time.perf_counter()\n",
        "        GS_time = toc - tic\n",
        "        tic = time.perf_counter()\n",
        "        RGS_Q, RGS_R = algo_2(W, sketch_mat)\n",
        "        toc = time.perf_counter()\n",
        "        RGS_time = toc - tic\n",
        "        time_diff = GS_time - RGS_time\n",
        "    #Finding and comparing the accuracy of the two methods\n",
        "        GS_results = W - mat_mul(GS_Q, GS_R)\n",
        "        GS_Ortho = np.identity(np.shape(W)[1]) - GS_Q.T @ GS_Q\n",
        "        RGS_results = W - mat_mul(RGS_Q, RGS_R)\n",
        "        RGS_Ortho = np.identity(np.shape(W)[1]) - RGS_Q.T @ RGS_Q\n",
        "        GS_norm = np.linalg.norm(GS_results)/np.linalg.norm(W)\n",
        "        RGS_norm = np.linalg.norm(RGS_results)/np.linalg.norm(W)\n",
        "        GS_Onorm = np.linalg.norm(GS_Ortho)/(np.sqrt(np.shape(W)[1]))\n",
        "        RGS_Onorm = np.linalg.norm(RGS_Ortho)/(np.sqrt(np.shape(W)[1]))\n",
        "        accuracy = (GS_norm, RGS_norm, GS_Onorm, RGS_Onorm)\n",
        "    #Setting results\n",
        "        results.append(accuracy)\n",
        "        times.append(time_diff)\n",
        "    return results, times"
      ],
      "metadata": {
        "id": "wywAtxO3UNsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code tests algo_2 against reduced_QR."
      ],
      "metadata": {
        "id": "oi4suoW-Uy_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "m = 5\n",
        "k = 7\n",
        "W = np.random.rand(n, m)\n",
        "iter = 1\n",
        "\n",
        "\n",
        "#run tests\n",
        "results, times = RGS_testing_2(iter, W, k)\n",
        "\n",
        "#print results\n",
        "for i in range(iter):\n",
        "    print(\"On iteration\", i)\n",
        "    print(\"The accuracy difference was: \" + str(results[i]))\n",
        "    print(\"The time difference was: \" + str(times[i]))\n",
        "    if times[i] < 0:\n",
        "        print(\"Gram Schmidt was quicker than RGS here.\")\n",
        "    elif times[i] == 0:\n",
        "        print(\"RGS and GS took the same time here.\")\n",
        "    else:\n",
        "        print(\"RGS was quicker than GS here.\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2JSbr0NUiXZ",
        "outputId": "ac66cd3b-7a07-400c-c5fd-90fad42eb9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On iteration 0\n",
            "The accuracy difference was: (7.947338315729995e-17, 6.0412611954036e-17, 6.599425734868943e-16, 3.0599246930938434e-16)\n",
            "The time difference was: -0.00013412200496532023\n",
            "Gram Schmidt was quicker than RGS here.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, it seems that algo_2 runs much slower than rand_QR. However, the accuracy is much better. While the intention of randomized GMRes is to eventually speed up computation time, it is not helpful if that is achieved at the loss of accuracy. For that reason, we will continue to use algo_2."
      ],
      "metadata": {
        "id": "Z8XofEepWOsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Randomized GMRes"
      ],
      "metadata": {
        "id": "UWe6o8kxVYHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grigori & Balabanov Algorithms"
      ],
      "metadata": {
        "id": "H8w2hY0TVbSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RGMRes implementation developed was based on the following two algorithms from the Grigori & Balabanov paper, along with the following minimization step to calculate a new guess after each iteration.\n",
        "\n",
        "<img src='https://i.imgur.com/ewbMXkZ.png'>\n",
        "\n",
        "<img src='https://i.imgur.com/bVKQtyD.png'>\n",
        "\n",
        "<img src='https://i.imgur.com/9gxHgff.png'>"
      ],
      "metadata": {
        "id": "q39E1tUpVfgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(3,3)\n",
        "A[:,:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss4GzHLyIKV3",
        "outputId": "03f0d16e-a0c6-4b3c-f542-1b46e2c9517d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7670881 , 0.2475551 , 0.57909153],\n",
              "       [0.41238268, 0.92254861, 0.00900287],\n",
              "       [0.73929993, 0.53187073, 0.3744976 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the above algorithms, and using the Sauer GMRes implementation to guide the logic of this implementation's development, the following RGMRes was developed."
      ],
      "metadata": {
        "id": "pO5J9aNxXNUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Randomized GMRes Implementation"
      ],
      "metadata": {
        "id": "U0cC5u86AX_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is the minimization step of the randomized GMRes algorithm."
      ],
      "metadata": {
        "id": "SfL-5SAJXvyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: arrays A, Q, R, sketch_mat\n",
        "#Returns: array x\n",
        "def find_x(A, Q, R, sketch_mat):\n",
        "    #Getting sizes of matrices\n",
        "    n = len(Q)\n",
        "    m = len(Q[0])\n",
        "\n",
        "    #Minimize function\n",
        "    b = np.zeros((m,1))\n",
        "    b[0] = R[0,0]\n",
        "\n",
        "    print(\"b\")\n",
        "    print(b)\n",
        "\n",
        "    sketched_AQ = my_sketch(sketch_mat, A) #kxn with sketching, nxn without\n",
        "    sketched_AQ = np.dot(sketched_AQ, Q[:,:m]) #kxm-1 with sketching, nxm-1 without\n",
        "    sketched_b = my_sketch(sketch_mat, Q) #kxm with sketching, nxm without\n",
        "    sketched_b = np.dot(sketched_b, b) #kx1 with sketching, mx1 without\n",
        "\n",
        "    y = np.linalg.lstsq(sketched_AQ, sketched_b)[0] #kxm-1 * y  -  kx1 => y = m-1x1, nxm-1 * y  -  mx1 => m-1x1\n",
        "\n",
        "    print(\"sketched_b\")\n",
        "    print(sketched_b)\n",
        "    print(\"sketched_AQ\")\n",
        "    print(sketched_AQ)\n",
        "\n",
        "    print(\"y\")\n",
        "    print(y)\n",
        "\n",
        "    x = np.dot(Q[:,:m],y) #nx1\n",
        "\n",
        "    print(\"x\")\n",
        "    print(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "jgITeUHkX16K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code implements RGMRes. It also defines a my_dot function so the user can decide whether to use sketching or not."
      ],
      "metadata": {
        "id": "UHleHEMmX5hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RGS-Arnoldi GMRes\n",
        "#Parameters: nxm array A, nx1 array b, kxn array sketch_mat, bool sketch\n",
        "#Returns: nxm factor array Q_m, mxm upper triangular factor R_m, result array X\n",
        "def my_random_gmres(A, b, sketch_mat, sketch = False):\n",
        "    \n",
        "    if (sketch):\n",
        "      def my_sketch(sketch_mat, mat):\n",
        "        return sketch_mat @ mat\n",
        "    else:\n",
        "        def my_sketch(sketch_mat, mat):\n",
        "          return mat\n",
        "\n",
        "\n",
        "\n",
        "    #Getting sizes of matrices\n",
        "    n = len(A)\n",
        "    m = len(A[0])\n",
        "\n",
        "    #3.1: Set w_1 = b\n",
        "    W = b\n",
        "    W_1 = b\n",
        "    #3.2: Perform 1st iteration of Algorithm 2\n",
        "    Q, R = algo_2(W, sketch_mat)\n",
        "    Q_1, R_1 = reduced_QR(W_1)\n",
        "\n",
        "    for i in range(1, m):\n",
        "        #3.3: Compute w_i = Aq_i-1\n",
        "        w_i = np.dot(A,Q[:,[i-1]])\n",
        "        W = np.hstack((W, w_i))\n",
        "        w_i_1 = np.dot(A,Q_1[:,[i-1]])\n",
        "        W_1 = np.hstack((W_1, w_i_1))\n",
        "\n",
        "        #3.4: Perform i-th iteration of Algorithm 2\n",
        "        Q, R = algo_2(W, sketch_mat)\n",
        "        Q_1, R_1 = reduced_QR(W_1)\n",
        "\n",
        "        print(\"Algo 2 Q\")\n",
        "        print(Q)\n",
        "        print(\"Reduced QR Q\")\n",
        "        print(Q_1)\n",
        "        print(\"Algo 2 R\")\n",
        "        print(R)\n",
        "        print(\"Reduced QR R\")\n",
        "        print(R_1)\n",
        "\n",
        "        #Minimize step to find next x guess\n",
        "        print(\"Algo 2 Find x\")\n",
        "        x = find_x(A, Q, R, sketch_mat)\n",
        "        print(\"Reduced QR find x\")\n",
        "        x_1 = find_x(A, Q_1, R_1, sketch_mat)\n",
        "\n",
        "        #save array of errors between each successive guess instead of\n",
        "        #saving all x guesses\n",
        "\n",
        "    return Q, R, x, x_1"
      ],
      "metadata": {
        "id": "TRqs2zfZX4rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function allows us to easily test the error of x guesses."
      ],
      "metadata": {
        "id": "0vmWwoRTmVEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to compare x vectors\n",
        "def xCompare(x1, x2, xTrue = 0):\n",
        "  compError = abs(x1 - x2)"
      ],
      "metadata": {
        "id": "69rewrE9mYua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code tests my_random_gmres."
      ],
      "metadata": {
        "id": "V5aD5Lg1Ckj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = 3\n",
        "#A = np.random.rand(size,size)\n",
        "A = np.array([[-7,8,1],[6,-3,2],[5,-1,-4]])\n",
        "#x_true = np.random.rand(size,1)\n",
        "x_true = np.array([[-5],[-6],[9]])\n",
        "b = np.dot(A,x_true)\n",
        "sketch_mat = Theta_Matrix(size,size)\n",
        "sketch = False\n",
        "Q, R, x, x_1 = my_random_gmres(A, b, sketch_mat, sketch)\n",
        "print(\"x true\")\n",
        "print(x_true)\n",
        "print(\"RGMRes x\")\n",
        "print(x)\n",
        "print(\"reduced QR x\")\n",
        "print(x_1)\n",
        "#print((x.reshape(size,1)-x_true)/np.linalg.norm(x_true))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaPqYkPBCoIp",
        "outputId": "c170595b-5233-4110-812f-3eaf08eccf6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algo 2 Q\n",
            "[[-0.07211012  0.04481374]\n",
            " [ 0.10816519 -0.99274687]\n",
            " [-0.99151421 -0.11155884]]\n",
            "Reduced QR Q\n",
            "[[-0.07211012  0.04481374]\n",
            " [ 0.10816519 -0.99274687]\n",
            " [-0.99151421 -0.11155884]]\n",
            "Algo 2 R\n",
            "[[55.47071299 -3.79135522]\n",
            " [ 0.          2.34711601]]\n",
            "Reduced QR R\n",
            "[[55.47071299 -3.79135522]\n",
            " [ 0.          2.34711601]]\n",
            "Algo 2 Find x\n",
            "b\n",
            "[[55.47071299]\n",
            " [ 0.        ]]\n",
            "sketched_b\n",
            "[[ -4.]\n",
            " [  6.]\n",
            " [-55.]]\n",
            "sketched_AQ\n",
            "[[ 0.37857815 -8.36723003]\n",
            " [-2.74018472  3.0240054 ]\n",
            " [ 3.49734102  1.66305096]]\n",
            "y\n",
            "[[-10.92835053]\n",
            " [ -1.23858418]]\n",
            "x\n",
            "[[ 0.73253912]\n",
            " [ 0.0475335 ]\n",
            " [10.97378982]]\n",
            "Reduced QR find x\n",
            "b\n",
            "[[55.47071299]\n",
            " [ 0.        ]]\n",
            "sketched_b\n",
            "[[ -4.]\n",
            " [  6.]\n",
            " [-55.]]\n",
            "sketched_AQ\n",
            "[[ 0.37857815 -8.36723003]\n",
            " [-2.74018472  3.0240054 ]\n",
            " [ 3.49734102  1.66305096]]\n",
            "y\n",
            "[[-10.92835053]\n",
            " [ -1.23858418]]\n",
            "x\n",
            "[[ 0.73253912]\n",
            " [ 0.0475335 ]\n",
            " [10.97378982]]\n",
            "Algo 2 Q\n",
            "[[-0.07211012  0.04481374 -0.99638941]\n",
            " [ 0.10816519 -0.99274687 -0.05247799]\n",
            " [-0.99151421 -0.11155884  0.06673981]]\n",
            "Reduced QR Q\n",
            "[[-0.07211012  0.04481374 -0.99638941]\n",
            " [ 0.10816519 -0.99274687 -0.05247799]\n",
            " [-0.99151421 -0.11155884  0.06673981]]\n",
            "Algo 2 R\n",
            "[[55.47071299 -3.79135522 -0.71848454]\n",
            " [ 0.          2.34711601 -3.56256685]\n",
            " [ 0.          0.          8.2893174 ]]\n",
            "Reduced QR R\n",
            "[[55.47071299 -3.79135522 -0.71848454]\n",
            " [ 0.          2.34711601 -3.56256685]\n",
            " [ 0.          0.          8.2893174 ]]\n",
            "Algo 2 Find x\n",
            "b\n",
            "[[55.47071299]\n",
            " [ 0.        ]\n",
            " [ 0.        ]]\n",
            "sketched_b\n",
            "[[ -4.]\n",
            " [  6.]\n",
            " [-55.]]\n",
            "sketched_AQ\n",
            "[[ 0.37857815 -8.36723003  6.6216418 ]\n",
            " [-2.74018472  3.0240054  -5.68742288]\n",
            " [ 3.49734102  1.66305096 -5.19642832]]\n",
            "y\n",
            "[[-9.21206836]\n",
            " [ 4.72838295]\n",
            " [ 5.89747329]]\n",
            "x\n",
            "[[-5.]\n",
            " [-6.]\n",
            " [ 9.]]\n",
            "Reduced QR find x\n",
            "b\n",
            "[[55.47071299]\n",
            " [ 0.        ]\n",
            " [ 0.        ]]\n",
            "sketched_b\n",
            "[[ -4.]\n",
            " [  6.]\n",
            " [-55.]]\n",
            "sketched_AQ\n",
            "[[ 0.37857815 -8.36723003  6.6216418 ]\n",
            " [-2.74018472  3.0240054  -5.68742288]\n",
            " [ 3.49734102  1.66305096 -5.19642832]]\n",
            "y\n",
            "[[-9.21206836]\n",
            " [ 4.72838295]\n",
            " [ 5.89747329]]\n",
            "x\n",
            "[[-5.]\n",
            " [-6.]\n",
            " [ 9.]]\n",
            "x true\n",
            "[[-5]\n",
            " [-6]\n",
            " [ 9]]\n",
            "RGMRes x\n",
            "[[-5.]\n",
            " [-6.]\n",
            " [ 9.]]\n",
            "reduced QR x\n",
            "[[-5.]\n",
            " [-6.]\n",
            " [ 9.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are still in the process of debugging the RGMRes code. Ideally, when the code runs properly, we can easily switch between GMRes and RGMRes to compare the two."
      ],
      "metadata": {
        "id": "FiPFLi1JX9pg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results & Discussion"
      ],
      "metadata": {
        "id": "x-G6a00ZYVvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do not have significant results to show since our RGMRes implementation does not yet run properly."
      ],
      "metadata": {
        "id": "TqwN_UOXYZfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion"
      ],
      "metadata": {
        "id": "wk3AIQj8YfH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do not have significant conclusions to draw since our RGMRes implementation does not yet run properly."
      ],
      "metadata": {
        "id": "VnwnYAcBYf8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bibliography"
      ],
      "metadata": {
        "id": "tgWK5xc8GUCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ali_m. (2015, November 5). *Getting the number of iterations of scipy's gmres iterative method*. Stack Overflow. https://stackoverflow.com/questions/33512081/getting-the-number-of-iterations-of-scipys-gmres-iterative-method\n",
        "\n",
        "Balabanov, O., & Grigori, L. (2022, January 18). *Randomized Gram-Schmidt process with applications to GMRes.*\n",
        "\n",
        "Batchelder, W., Matrinez, V., & Vue, J. *NREL - rGS Project.*\n",
        "\n",
        "Sauer, T. (2018). Generalized Minimum Residual (GMRES) Method. *Numerical Analysis* (3rd ed. pp. 235-239). Pearson.\n",
        "\n",
        "Wikimedia Foundation. (2022, Feburary 22). *Generalized minimal residual method.* Wikipedia. https://en.wikipedia.org/wiki/Generalized_minimal_residual_method"
      ],
      "metadata": {
        "id": "aqrhxJEJGZyr"
      }
    }
  ]
}